\chapter{Statistics Tool Box}
\label{chap:stat}

The data we collect is stochastic: quantum mechanics is not deterministic, the particle content result of an interaction follows probabilistic laws. Furthermore, experimental effects need to be taken into account. Therefore, a proper statistical treatment is essential to extract quantitative statements from the observed data. This section describes the main statistical procedures that are used to obtain the results described in Chapter \ref{chap:strong_prod} and Chapter \ref{chap:ewk_prod}. The two main topics discussed are parameter estimation (Section \ref{sec:stat:pe}), that has the aim to determine the value of the input parameters that allows to best describe data, and hypothesis testing (Section \ref{sec:stat:ht}), that checks the plausibility of models against the observed data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Parameter Estimation}
\label{sec:stat:pe}

The Likelihood function and the parameter estimation technique based on its maximization are described in this section.

\subsection{The Likelihood Function}

\begin{equation}
\label{eq:stat:exp}
E[n_i] = \mu s_i + b_i \
\end{equation}


\begin{equation}
\label{eq:stat:lik_no_sys}
L(\mu, \vec{\theta}) =
\prod_{j=1}^N \frac{ (\mu s_{j} +
b_{j} )^{n_{j}} }{ n_{j}! }
e^{- (\mu s_{j} + b_{j}) } 
\end{equation}

\subsection{Inclusion of Systematic Uncertainties}

The prediction on the expected number of events is affected by systematic and statistical uncertainties, that are incorporated in the Likelihood in the form of nuisance parameters (NPs).

\par\smallskip

The factorization holds only as long as the data used to derive the constraints on the NPs is statistically independent from the data in the analysis and not affected by the potential presence of the signal under study.

\subsubsection*{Functional Forms of the Prior}

\iffalse
% this is taken from "Asymptotic formulae for likelihood-based tests of new physics"
\begin{equation}
\label{eq:stat:lik_boh}
L(\mu, \vec{\theta}) =
\prod_{j=1}^N \frac{ (\mu s_{j} +
b_{j} )^{n_{j}} }{ n_{j}! }
e^{- (\mu s_{j} + b_{j}) }   \;\;
\prod_{k=1}^M \frac{ u_k^{m_{k}}} { m_{k}! } \,
e^{- u_k }  \;.
\end{equation}
\fi

\begin{equation}
\label{eq:stat:lik_sys}
L(\mu, \vec{\theta}) =
\prod_{j=1}^N \frac{ (\mu s_{j} +
b_{j} )^{n_{j}} }{ n_{j}! }
e^{- (\mu s_{j} + b_{j}) }   \;\;
\prod_{k=1}^M \rho( \theta_k) \
\end{equation}

\subsubsection*{Correlation and Profiling}

The post-fit values of the NPs can be compared to the pre-fit values. A central value close to 0 and an uncertainty close to 1 indicates that the fit does not have enough statistical power to profile the uncertainties. If the central values is different from 0, it means that the best value is different from the nominal one; the modified MC will have a better agreement with data than the original one. If the post-fit uncertainty on one NP is smaller than 1, it means that the original assigned uncertainty was too large and the fit was able to constrain the uncertainty on that NP.
% The effect of a specific systematic is not compatible with the range allowed by the data statistics 

When multiple NPs have a similar effect on the background prediction, the total variation obtained as a sum of their effects can be larger than what allowed by data. The individual effects can not be disentangled and constrained individually, but a correlation between them produce a total variation that is compatible with what observed in data. % chiarareco:;\ un po' copiato da Javier, rifrasare!

\subsubsection*{Interpolation}

\subsection{Profiled Likelihood Ratio}

\begin{equation}
\label{eq:stat:prl}
\prl = \frac{ L(\mu,
\hat{\hat{\theta}}) } {L(\hat{\mu}, \hat{\theta}) } \;.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Hypothesis Testing}
\label{sec:stat:ht}

Hypothesis testing is the statistical procedure that allows to confirm or reject a specific model. In the case of high-energy physics, this allows to discover or exclude a BSM theory. 

\begin{itemize}
\item H$_0$ is the null hypothesis, that corresponds to SM only
\item H$_1$ is the test hypothesis, that corresponds to the SM with the addition of the BSM processes under test
\end{itemize}

\noindent The test hypothesis can be generalized by including the signal strength $\mu$, that acts as a cross-section scaling; $\mu$=1 corresponds to the BSM process with its theoretical cross section, while $\mu$=0 is the SM.

\subsection{Test Statistics and p-value}

The test statistics quantifies the compatibility of the observed data with a specific model.
A p-value can be extracted from the distribution of the test statistics according to a certain hypothesis. For each hypothesis under test and given an observation, the p-value corresponds to the probability of having another observation more extreme of the current one.

\iffalse
Points to discuss
- correspondence between p-values and sigma
- arbitrary choice 
- note that excluding one hypothesis does not mean stating that the other is true
- using 95 CLs for discovery would mean claiming 1/20 of the times that the SM is false
- ATTENZIONE: al momento ho delle inconsistenza della definizione di t_mu: e' l'integrale da -inf a t_obs o da t_obs a +inf
\fi 

\begin{equation}
\label{eq:stat:sig}
Z = \Phi^{-1}(1-p) \
\end{equation}

\subsection{Test Statistics when using PRL}

\begin{equation}
\label{eq:stat:tmu}
t_{\mu} = -2 \log \prl
\end{equation}


\begin{equation}
\label{eq:stat:pmu}
p_{\mu} = \int_{t_{\mu,{\rm obs}}}^{\infty} f(t_{\mu} | \mu ) \,
d t_{\mu} \;,
\end{equation}

\subsubsection*{Test Statistic for Discovery}

The discovery test statistics $q_{0}$ used to quantify the level of disagreement of data with the B-only hypothesis in case of an excess is defined as:

\begin{equation}
\label{eq:stat:q0}
q_{0} =
\left\{ \! \! \begin{array}{ll}
               - 2 \ln \lambda(0)
               & \quad \hat{\mu} \ge 0 \;, \\*[0.3 cm]
               0 & \quad \hat{\mu} < 0  \;,
              \end{array}
       \right.
\end{equation}
 
\noindent The reason to assign the value 0 to the test statistic when $\hat{\mu} < 0$ is to avoid excluding the B-only hypothesis in case of a deficit. In fact, $\hat{\mu} < 0$ can indeed be symptomatic of a non correct B-only hypothesis (e.g. a systematic error), but it does not indicate the presence of a signal, which is what we want to highlight with this test statistics. Note that, since \prl assumes values between 0 and 1, \qzero is positive definite. The associated discovery p-value $p_{0}$ is:

\begin{equation}
\label{eq:stat:p0}
p_{0} = \int_{q_{0,{\rm obs}}}^{\infty} f(q_{0} | 0 ) \, d q_{0} \;.
\end{equation}

\subsubsection*{Test Statistics for Exclusion}

When investigating the exclusion of the test hypothesis, we want a test statistics that does not penalize an excess. The exclusion test statistics \qmu is therefore defined as:

\begin{equation}
\label{eq:stat:qmu}
q_{\mu} =
\left\{ \! \! \begin{array}{ll}
               - 2 \ln \lambda(\mu)  & \hat{\mu} \le \mu  \;, \\*[0.2 cm]
               0 & \hat{\mu} > \mu \;,
              \end{array}
       \right.
\end{equation}

\noindent This test statistic, also known as one-sided PRL, is the default one used in the analyses described in the next two chapters. \pmu is consequently defined as the integral above the observed value: 

\begin{equation}
\label{eq:stat:pmu}
p_{\mu} = \int_{q_{\mu,{\rm obs}}}^{\infty} f(q_{\mu} | \mu ) \, d q_{\mu} \;.
\end{equation}

% chiara: e' vero?
% credo che dipenda dal fatto che la L sia simmetrica rispetto a eccessi o deficit
%\noindent Note that, despite the very similar integration formula in \ref{eq:stat:p0} and \ref{eq:stat:pmu}, $p_{\mu, \mu=0}$ is different from \pzero because of the difference in definition between the exclusion and discovery test statistics.

\subsubsection*{Uncapped Test Statistics}

The strategy described above leads to a loss of information when the test statistic is set to 0. A solution is obtained by uncapping the test statistic and, instead of assigning a 0 to the situations we do not want to penalize, assign them a negative value. This is achieved with the $r_0$ and $r_\mu$ test statistics. As an example, the definition for $r_\mu$ is:
\begin{equation}
\label{eq:rmu}
r_{\mu} =
\left\{ \! \! \begin{array}{ll}
               - 2 \ln \lambda(\mu)  & \hat{\mu} \le \mu  \;, \\*[0.2 cm]
               + 2 \ln \lambda(\mu)  & \hat{\mu} \le \mu  \;,
              \end{array}
       \right.
\end{equation}

 
\subsubsection*{Allow Only Positive Signals}

The alternate PRL, $\tilde{\lambda}({\mu})$, is designed to take into account the fact that, in most physical cases, only positive $\mu$ have a physical meaning. In this case, when $\hat{\mu} < 0$ , the best physical value is 0, and the alternate PRL is defined as: 

\begin{equation}
\label{eq:stat:lik:alpexcl}
\tilde{\lambda}({\mu}) =
\left\{ \! \! \begin{array}{ll}
               \frac{ L(\mu,
               \hat{\hat{\vec{\theta}}}(\mu)) }
               {L(\hat{\mu}, \hat{\vec{\theta}}) }
                 & \hat{\mu} \ge 0 , \\*[0.3 cm]
                \frac{ L(\mu,
               \hat{\hat{\vec{\theta}}}(\mu)) }
               {L(0, \hat{\hat{\vec{\theta}}}(0)) }
 & \hat{\mu} < 0 \;.
              \end{array}
       \right.
\end{equation}

\noindent The corresponding test statistics are indicated with $\tilde{q}$ and are defined as in Eq \ref{eq:stat:q0} and Eq \ref{eq:stat:qmu} after substituting $\lambda({\mu}) \rightarrow \tilde{\lambda}({\mu})$.

\iffalse
% this equation in the original paper uses the notation t and not q
\begin{equation}
\label{eq:stat:q:excl}
\qmu = - 2 \ln \tilde{\lambda}(\mu) =
\left\{ \! \! \begin{array}{ll}
               - 2 \ln \frac{L(\mu, \hat{\hat{\vec{\theta}}}(\mu))}
                {L(0, \hat{\hat{\theta}}(0))}
                & \quad \hat{\mu} < 0  \;, \\*[0.2 cm]
               -2 \ln \frac{L(\mu, \hat{\hat{\vec{\theta}}}(\mu))}
                {L(\hat{\mu}, \hat{\vec{\theta}})}
&  \quad \hat{\mu} \ge 0  \;.
              \end{array}
       \right.
\end{equation}
\fi

\subsection{The CLs Method}

The \cls method \cite{JUNK1999435}

\begin{equation}
\cls = \dfrac{\pmu}{1 - \pzero}
\end{equation}

\subsection{Distribution of the Test Statistic}

To compute the p-value associated with the observed value of a test statistics $t$, we need the PDF of $t$ assuming that the signal hypothesis $H_\mu$ is true, $ f(t | \mu ) $. The distribution of the test statistics can be obtained with pseudo-experiments or, in the case of large statistics, with the asymptotic approximation. 

\subsubsection*{Pseudo-experiments}


\subsubsection*{Asymptotic Approximation}
Asymptotic approximation \cite{Cowan2011}

\noindent Wald's approximation \cite{Wald1943}

\begin{equation}
\label{eq:wald}
t_{\mu} = -2 \ln \lambda(\mu)
= \frac{(\mu - \hat{\mu})^2}{\sigma^2} + {\cal  O}(1/\sqrt{N}) \;.
\end{equation}

 $t_{\mu} = -2 \ln \lambda(\mu)$ is distributed according to a noncentral chi-square distribution with one degree of freedom:

\begin{equation}
\label{eq:stat:ftmulambda}
f(t_{\mu};\Lambda) = \frac{1}{2 \sqrt{t_{\mu}}} \frac{1}{\sqrt{2 \pi}}
\left[ \exp \left( - \frac{1}{2}
\left( \sqrt{t_{\mu}} + \sqrt{\Lambda} \right)^2 \right) +
\exp \left( - \frac{1}{2} \left( \sqrt{t_{\mu}} - \sqrt{\Lambda} \right)^2
\right) \right] \;,
\end{equation}

\noindent where the noncentrality parameter $\Lambda$ is

\begin{equation}
\label{eq:stat:noncentrality}
\Lambda = \frac{(\mu - \mu^{\prime})^2}{\sigma^2} \;.
\end{equation}


\section{A Simplified Walk-through Example}

